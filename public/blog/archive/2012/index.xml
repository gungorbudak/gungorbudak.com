<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2012 on Güngör Budak</title>
    <link>https://www.gungorbudak.com/blog/archive/2012/</link>
    <description>Recent content in 2012 on Güngör Budak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 09 Aug 2012 09:15:00 +0300</lastBuildDate><atom:link href="https://www.gungorbudak.com/blog/archive/2012/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SRS&#39;de Coklu Arama Yapmak</title>
      <link>https://www.gungorbudak.com/blog/2012/08/09/srsde-coklu-arama-yapmak/</link>
      <pubDate>Thu, 09 Aug 2012 09:15:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/08/09/srsde-coklu-arama-yapmak/</guid>
      <description>Inceleme yapan scriptin en son hali, oncekilere gore daha fazla okuma inceliyor oldugu icin her okuma icin SRS uzerinde isim aramak oldukca zaman alan bir islemdi. Oyle ki, son inceleme 4 gun surdu.
Bunu azaltmak icin inceleme scriptini tamamen degistirdim. Oncelikle her zaman oldugu gibi esik degerini gecenleri aliyor ama direkt bunlarin ID numaralarini bir dizide (array) listeliyorum. Daha sonra bu listenin herbir elemanini boru karakteri ile ayirarak bir string haline getiriyorum.</description>
    </item>
    
    <item>
      <title>MegaBLAST Sonuclarini Incelemek - Parsing</title>
      <link>https://www.gungorbudak.com/blog/2012/08/09/megablast-sonuclarini-incelemek-parsing/</link>
      <pubDate>Thu, 09 Aug 2012 09:14:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/08/09/megablast-sonuclarini-incelemek-parsing/</guid>
      <description>Pipeline&amp;rsquo;da son asama, aranan dizilerin urettigi ciktilari baska bir script ile incelemek. Bu islemle herbir megablast dosyasi okunuyor, ve dizilerin name, identity, overlapping length gibi parametrelerinin degerleri saklanarak amaca yonelik sekilde ekrana yazdiriliyor.
Projemde HUSAR paketinde bulunan ve yukarida bahsettigim alanlari bana dizi olarak donduren Inslink adinda bir parser kullaniyorum. Bu parserin yaptigi tek sey, dosyayi okumak ve dosyadaki istenen alanlarin degerlerini saklamak.
Daha sonra ben bu saklanan degerleri, koda eklemeler yaparak gosteriyorum ve birkac ek kod ile de ihtiyacim olan anlamli sonuclar gosteriyorum.</description>
    </item>
    
    <item>
      <title>Kalite Satirinin Degerlendirilmesi - Quality Filter</title>
      <link>https://www.gungorbudak.com/blog/2012/08/09/kalite-satirinin-degerlendirilmesi/</link>
      <pubDate>Thu, 09 Aug 2012 08:48:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/08/09/kalite-satirinin-degerlendirilmesi/</guid>
      <description>Kirleten organizma (konaminant) analizi yapacak olan pipeline&amp;rsquo;i daha fazla gelistirmek, daha anlamli sonuclar elde etmek icin ilk adimlara (henuz fastq dosyasini isliyorken) kalite filtresi eklemeyi dusunduk. Boylece belirli bir esik degerinden dusuk okumalari daha o asamadan filtreleyerek daha guvenilir sonuclar elde elebilecegiz.
Bu kalite kontrolunu fastq dosyasinda her okumanin 4. satirini anlayarak yapacagiz. Bu 4. satir (aslinda okumanin dizileme kalite skoru), cesitli dizileme cihazlari tarafindan cesitli sekillerde yaziliyor (kodlaniyor) ve bu kodlamadan tekrar kalite skorunu elde ederek filtreleme uygulanmasi gerekiyor.</description>
    </item>
    
    <item>
      <title>Dorduncu Deneme Veriseti: Mus Musculus Genomu</title>
      <link>https://www.gungorbudak.com/blog/2012/08/03/dorduncu-deneme-veriseti-mus-musculus/</link>
      <pubDate>Fri, 03 Aug 2012 05:15:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/08/03/dorduncu-deneme-veriseti-mus-musculus/</guid>
      <description>Simdiye kadar ilk uc veriseti de insan genomuna aitti. Pipeline&amp;rsquo;i bu genomlarla deneyip, yer yer iyilestirmeler yaptim. Simdi ise baska organizmalarla da deneyip, daha fazla sonuc alip bunlari inceleyecegim ve gene gerekli iyilestirmeleri yapacagim.
Bu ilk farkli veriseti fareden geliyor. Mus Musculus tur adina ve ev faresi olarak yaygin isme sahip bu organizma da model organizma olarak calismalarda kullanildigi icin dizisi daha siklikla cikarilan diger bir organizma.
Bi dizilemeyi yapan, birlikte calistigim laboratuvardan cesitli BAM formatinda dizi dosyalari aldim.</description>
    </item>
    
    <item>
      <title>Inceleme Sonuclarini &#34;Ambiguous&#34; Olarak Ayirmak</title>
      <link>https://www.gungorbudak.com/blog/2012/08/02/inceleme-sonuclarini-ambiguous-olarak/</link>
      <pubDate>Thu, 02 Aug 2012 06:03:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/08/02/inceleme-sonuclarini-ambiguous-olarak/</guid>
      <description>Cesitli veritabanlarina karsi yaptigim aramalardan aldigim sonuclari incelerken, bunlari cesitli esik degerleri ile degerlendirmek ile beraber belirlenen esik degerlerinin uzerinde ya da altinda olan hitleri &amp;ldquo;Ambiguous&amp;rdquo; (belirsiz, cok anlamli) ya da &amp;ldquo;Unique&amp;rdquo; (essiz, tek) olarak ayirarak daha da anlamli hale getirmeye calisiyorum.
&amp;ldquo;Ambiguous&amp;rdquo; olarak, her bir megablast dosyasinda esik degerlerine uygun ancak birden fazla farkli organizmayi iceren hitleri etiketliyorum. Eger her esik degerine uygun hit, tek bir dosya icinde her zaman ayni organizmaya ait ise bu durumda yaptigim sey onu &amp;ldquo;unique&amp;rdquo; olarak etiketlemek.</description>
    </item>
    
    <item>
      <title>Ikinci Veriseti Inceleme Sonuclari</title>
      <link>https://www.gungorbudak.com/blog/2012/08/02/ikinci-veriseti-inceleme-sonuclari/</link>
      <pubDate>Thu, 02 Aug 2012 05:15:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/08/02/ikinci-veriseti-inceleme-sonuclari/</guid>
      <description>Daha az eslenemeyen okumalara sahip ikinci verisetinin incelemesini tamamladim. Bu oncekine gore daha iyi bir dizileme ornegi oldugu icin aldigim sonuclar da oldukca tutarliydi. Insan genomuna ait bir diziden inceleme sonra asagidaki sonuclari elde ettim.
LIST OF ORGANISMS AND THEIR NUMBER OF OCCURENCES Ambiguous hit 1323 Homo sapiens 312 Pan troglodytes 25 Pongo abelii 18 Nomascus leucogenys 17 Halomonas sp. GFAJ-1 7 Callithrix jacchus 4 Macaca mulatta 3 Oryctolagus cuniculus 2 Loxodonta africana 1 Cavia porcellus 1 &amp;ldquo;Ambiguous hit&amp;rdquo; tanimini baska bir yazida aciklayacagim.</description>
    </item>
    
    <item>
      <title>Yeni Verisetinin Incelenmesi</title>
      <link>https://www.gungorbudak.com/blog/2012/07/26/yeni-veri-setinin-incelenmesi/</link>
      <pubDate>Thu, 26 Jul 2012 08:32:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/26/yeni-veri-setinin-incelenmesi/</guid>
      <description>Pipeline&amp;rsquo;i tasarlama asamasinda deneme amacli kullandigim onceki verinin cok kotu olmasi sebebiyle yeni bir veriseti aldim. Elbette deneme asamasinda birden fazla, farkli karakterlerde verisetleri kullanmak yararlidir. Ancak onceki veriseti anlamli birkac sonuc veremeyecek kadar kotuydu diyebilirim. Ayrintilarina [buradan]({% post_url 2012-07-06-eslestirme-ve-eslesmeyen-okumalari %}) gozatabilirsiniz.
Yeni veriseti, gene bir insan genomu verisi ve BAM dosyasinin boyutu 1.8 GB ve icinde eslenebilen ve eslenemeyen okumalari bulunduruyordu. Ben bam2fastq araciyla hem bu BAM dosyasini FASTQ dosyasina cevirirken hem de eslenebilen okumalardan ayiklayarak 0.</description>
    </item>
    
    <item>
      <title>Birden Fazla Dizi Dosyalarindan MegaBLAST&#39;i Calistirmak</title>
      <link>https://www.gungorbudak.com/blog/2012/07/26/birden-fazla-dizi-dosyalarindan-megablast-calistirmak/</link>
      <pubDate>Thu, 26 Jul 2012 07:48:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/26/birden-fazla-dizi-dosyalarindan-megablast-calistirmak/</guid>
      <description>Asagidaki scripti, pipeline&amp;rsquo;in MegaBLAST aramasini daha hizli yapabilmek icin dusundugumuz bir teknige uygun olabilmesi icin yazdim. Yaptigi sey, her okuma icin olusturulmus ve formatlanmis dizi dosyalarini kullanarak veritabanlarinda belirtilen baslangic noktasi ve okuma sayisi ile arama yapmak.
#!user/local/bin/perl $database = $ARGV[0]; $dir = $ARGV[1]; #directory for sequences $sp = $ARGV[2]; #starting point $n = $ARGV[3] + $sp; while (1) { system(&amp;#34;blastplus -programname=megablast $dir/read_$sp.seq $database -OUTFILE=read_$sp.megablast -nobatch -d&amp;#34;); $sp++; last if ($sp == $n); } Burada her sey gercekten cok basit bir programlama ile isliyor.</description>
    </item>
    
    <item>
      <title>Tek FASTA Dosyasindan MegaBLAST&#39;i Calistirmak - Duzenli Ifadeler</title>
      <link>https://www.gungorbudak.com/blog/2012/07/23/tek-fasta-dosyasindan-megablast-calistirmak/</link>
      <pubDate>Mon, 23 Jul 2012 05:49:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/23/tek-fasta-dosyasindan-megablast-calistirmak/</guid>
      <description>Asagida MegaBLAST&amp;rsquo;i FASTA dosyasi okuyarak calistirmak ve sonuclari bir dizinde toplayabilmek amaciyla yazdigim Perl scripti ve onun aciklamasi var. Bu script tasarlamakta oldugum pipeline&amp;rsquo;in onemli bir parcasi. Bu script ilk yazdigim olan ve sadece bir FASTA dosyasi uzerinden tum okumalara ulasabilen script.
#!user/local/bin/perl $database = $ARGV[0]; $fasta = $ARGV[1]; #input file $sp = $ARGV[2]; #starting point $n = $ARGV[3] + $sp; if(!defined($n)){$n=12;} #set default number open FASTA, $fasta or die $!</description>
    </item>
    
    <item>
      <title>Unix&#39;te Perl Ile Bir Komut Ciktisini Okumak ve Duzenli Ifadeler</title>
      <link>https://www.gungorbudak.com/blog/2012/07/23/unixte-perl-ile-bir-komut-ciktisini-okumak/</link>
      <pubDate>Mon, 23 Jul 2012 05:06:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/23/unixte-perl-ile-bir-komut-ciktisini-okumak/</guid>
      <description>Daha once organizma isimlerini duzenli ifadelerle nasil cikardigimi anlatmistim. Burada, gene benzer bir seyden bahsedecegim ancak bu biraz daha fazla, ozel bir teknikle Perl&amp;rsquo;de yapilan, veri tabanindan bilgileri birden fazla satir halinde cikti olarak aldigim icin gerek duydugum cok yararli bir yontem. Mutlaka benzerini baska amaclarla da kullanabilir, yararlanabilirsiniz.
Bu ihtiyac, HUSAR gurubu tarafindan olusturulan honest veritabaninin organizma isimlerini direkt sunmamasi ancak birkac satir halinde gostermesi sebebiyle dogdu. Asagida bunun ornegini gorebilirsiniz.</description>
    </item>
    
    <item>
      <title>Duzenli Ifadeler ile Tur Ismini Elde Etmek</title>
      <link>https://www.gungorbudak.com/blog/2012/07/23/duzenli-ifadeler-ile-tur-ismini-elde/</link>
      <pubDate>Mon, 23 Jul 2012 04:19:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/23/duzenli-ifadeler-ile-tur-ismini-elde/</guid>
      <description>Projemin sonunda kullaniciya olasi kirleten organizmalarin adlarini (Latince tur isimleri) gosterecegim icin, MegaBLAST sonuclarindaki erisim numaralarini (accession number) kullanarak her dizi icin organizma adlarini elde etmem gerekiyor. Sequence Retrival System (SRS) adinda, HUSAR sunucularinda bulunan baska bir sistem ile bunu yapabiliyorum.
SRS&amp;rsquo;ten organizma adini ogrenebilmem icin Unix komut satirinda &amp;ldquo;getz&amp;rdquo; komutuyla birlikte veritabani ismi, erisim numarasi ve ogrenmek istedigim alani yazmam yetiyor. Asagida, bu isi yapabilen ornek bir kod bulabilirsiniz.</description>
    </item>
    
    <item>
      <title>Bir MegaBLAST Ciktisi Icerigi - RefSeq Veritabani</title>
      <link>https://www.gungorbudak.com/blog/2012/07/19/bir-megablast-ciktisi-icerigi-refseq/</link>
      <pubDate>Thu, 19 Jul 2012 09:35:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/19/bir-megablast-ciktisi-icerigi-refseq/</guid>
      <description>Asagida, deneme FASTA dosyasini refseq_genomic veritabaninda arayarak elde ettigim dosyadan, bir hitin ayrintilarini goruyoruz.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;refseq_genomic_complete3: AC_000033_0310 Continuation (311 of 1357) of AC_000033 from base 31000001 (AC_000033 Mus musculus strain mixed chromosome 11, alternate assembly Mm_Celera, whole genome shotgun sequence. 2/2012) Length = 110000 Score = 115 bits (58), Expect = 4e-22 Identities = 74/79 (93%), Gaps = 2/79 (2%) Strand = Plus / Minus Query: 1 ctctctctgtct-tctctctctctctgtctctctctctttctctctcttctctctctctc 59 |||||||||||| ||| ||||||||| ||||||||||| ||||||||||||||||||||| Sbjct: 89773 ctctctctgtctgtctttctctctctctctctctctctctctctctcttctctctctctc 89714 Query: 60 tttctctctgccctctctc 78 ||||||||| ||||||||| Sbjct: 89713 tttctctct-ccctctctc 89696 Ayrintilarda, ilk olarak &amp;gt;&amp;gt;&amp;gt;&amp;gt; karakterleriyle hit ile ilgili baslik bilgisi veriyor.</description>
    </item>
    
    <item>
      <title>MegaBLAST Aramasini Hizlandirma</title>
      <link>https://www.gungorbudak.com/blog/2012/07/16/megablast-aramasini-hizlandirma/</link>
      <pubDate>Mon, 16 Jul 2012 04:54:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/16/megablast-aramasini-hizlandirma/</guid>
      <description>Son zamanlarda sadece farkli veritabanlarinda, MegaBLAST&amp;rsquo;i en cabuk ve etkili bir sekilde calistirmanin yolunu ariyorum ve FASTA dosyasi olusturma asamasinda, gercekten cokca ise yarayan bir yontem danismanim tarafindan geldi.
Daha once tum dizilerin bulundugu tek bir FASTA dosyasindan arama yapiyordum ve bu zaman kaybina yol aciyordu. Her ne kadar dosya bir sefer acilsa da her seferinde dosya icinde satirlara gidip onu okuman, zaman alan bir islem. Bunu, dosyadaki her okumayi, ayri bir FASTA dosyasi haline getirerek cozduk.</description>
    </item>
    
    <item>
      <title>Veritabanina Gore Bir Komutun Calisma Suresi - CPU Runtime</title>
      <link>https://www.gungorbudak.com/blog/2012/07/16/veritabanina-gore-bir-komutun-calisma/</link>
      <pubDate>Mon, 16 Jul 2012 04:17:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/16/veritabanina-gore-bir-komutun-calisma/</guid>
      <description>Calisilan dosyalar, veritabanları buyuk olunca ve yeterince bilgisayar gucune sahip olmayınca, her seyden once olcmemiz gereken nasil en etkili ve kisa surede sonucu alabiliyor olmamizdir.
Özellikle projemde, farkli veritabanları ve farkli parametreler kullanarak, bunları arastiriyorum.
Şimdilik dort veritabani deniyorum, bunlar: nrnuc, ensembl_cdna, honest ve refseq_genomic. Ayrica, bunu farkli iki kelime uzunluğuna gore de yapacagim. Kelime uzunluğu (word size) MegaBLAST&amp;rsquo;in ararken tam olarak eslestirecegi baz cifti sayisi. Yani elimde 151 baz ciftine sahip bir dizilim varsa, ve eger kelime uzunluğu 50 olarak belirlenmişse, bu 151 baz cifti icinden herhangi bir yerden baslayan ama arka arkaya en az 50 bazin dizilendiği kisimlar aranacak.</description>
    </item>
    
    <item>
      <title>Veritabani Secimi</title>
      <link>https://www.gungorbudak.com/blog/2012/07/13/veritabani-secimi/</link>
      <pubDate>Fri, 13 Jul 2012 09:29:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/13/veritabani-secimi/</guid>
      <description>Bu projedeki amacim olasi kirleten organizmalari (kontaminantlari) bulmak. Dolayisiyla genis bir veritabanina ihtiyacim var. Ancak veritabanini genis tutmak boyle bir avantaj sagliyorken, her dizi icin o veritabaninda arama yapmak oldukca fazla bilgisayar gucu ve zaman gerektiriyor. Bu yuzden projemi gelistirirken, cesitli veritabanlarini da inceliyorum. Ve ayrica bunlari nasil kisitlayarak, amacim icin en uygun hale getirebilecegimi arastiriyorum.
Ilk olarak NCBI&amp;rsquo;in Reference Sequence (Kaynak Dizi ya da Referans Sekans) &amp;ndash; RefSeq &amp;ndash; veritabaniyla basladim.</description>
    </item>
    
    <item>
      <title>FASTQ&#39;dan FASTA&#39;ya Donusturme Perl Scripti</title>
      <link>https://www.gungorbudak.com/blog/2012/07/13/fastqdan-fastaya-donusturme-perl/</link>
      <pubDate>Fri, 13 Jul 2012 05:05:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/13/fastqdan-fastaya-donusturme-perl/</guid>
      <description>FASTQ ve FASTA formatlari aslinda ayni bilgiyi iceren ancak birinde sadece herbir dizi icin iki satir daha az bilginin bulundugu dosya formatlari. Projemde onemli olan diger bir farklari ise FASTA formatinin direkt olarak MegaBLAST arama yapilabilmesi. Iste bu yuzden, genetik dizilim yapan makinelerin olusturdugu FASTQ formatini FASTA&amp;rsquo;ya cevirmem gerekiyor. Ve bu script pipeline&amp;rsquo;in ilk adimi.
Aslinda deneme amacli aldigim genetk dizilimin, bana bunu ulastiran tarafindan eslestirmesinin yapilmadigi icin, bir on adim olarak bu eslestirmeyi yapmistim.</description>
    </item>
    
    <item>
      <title>Eşleştirme ve Eşleşmeyen Okumaları Çıkarma Sonuçları</title>
      <link>https://www.gungorbudak.com/blog/2012/07/06/eslestirme-ve-eslesmeyen-okumalari/</link>
      <pubDate>Fri, 06 Jul 2012 19:46:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/06/eslestirme-ve-eslesmeyen-okumalari/</guid>
      <description>Daha önce verinin sadece bir kısmı ile çalışıyordum ancak artık tamamıyla çalışacağım. Bu yüzden bana sıkıştırılmış halde gelen veriyi direkt çalışma klasörüme çıkardım ve onun üzerinden işlemler yaptım.
Başlangıç (FASTQ) dosyamın boyutu 2153988289 bayt (2 GB). Ve bwa aracılığıyla eşleştirmeden sonra toplamda 6004193 dizilim, ya da okuma, (sequences ya da reads) ortaya çıktı. Daha sonra eşleşmeyen okumaları çıkarmam sonrasında toplam okuma sayısı 551065 kadar azaldı ve 5493128 oldu. Yani verinin %9.</description>
    </item>
    
    <item>
      <title>BWA İle Eşleştirme (Mapping - Alignment)</title>
      <link>https://www.gungorbudak.com/blog/2012/07/06/bwa-ile-eslestirme-mapping-alignment/</link>
      <pubDate>Fri, 06 Jul 2012 19:40:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/06/bwa-ile-eslestirme-mapping-alignment/</guid>
      <description>Bunu daha önce yazmayı unutmuşum. Aslında bahsetmiştim ancak nasıl yapıldığına dair bir şeyler yazmamışım ayrıca örnek komutlar da eklememişim.
BWA elimizdeki (FASTQ formatındaki) DNA dizilimini, referans genomunu (projemde bu insan genomu) alarak bir .sai dosyası oluşturuyor. Bu dosya dizinin ve referans genomunun eşleşmesi ile ilgili bilgiler taşiyor ve bu bilgileri kullanarak eşleşmeyenleri ayırabiliyorum.
İlk olarak aşağıdaki komut ile .sai dosyamızı oluşturuyoruz.
bwa aln $NGSDATAROOT/bwa/human_genome37 ChIP_NoIndex_L001_R1_complete_filtered.fastq &amp;gt; complete_alignment.sai Oluşturduğumuz .sai dosyası çok da kullanışlı bir dosya değil, bu yüzden onu SAM dosyasına çevirerek, işlemlere devam ediyoruz.</description>
    </item>
    
    <item>
      <title>SAM Dosyası - BAM Dosyası - samtools</title>
      <link>https://www.gungorbudak.com/blog/2012/07/04/sam-dosyasi-bam-dosyasi-samtools/</link>
      <pubDate>Wed, 04 Jul 2012 20:36:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/04/sam-dosyasi-bam-dosyasi-samtools/</guid>
      <description>Aslında programlamam gereken pipeline direkt olarak eşleşmeyen okumalar üzerinden analizler yapacak. Ancak böyle bir veri bulamadiığım için, elimdeki tek veri eşleşen ve eşleşmeyen okumaları içerdiği için önce eşleşenlerden kurtulmam gerekti.
Bunu daha önce de belirttiğim gibi bwa eşleştiricisi (aligner - mapper) ile yapıyorum. bwa bir dizi işlemden sonra SAM dosyası oluşturuyor ancak benim FASTQ dosyasına ihtiyacım var. Bunun için SAM dosyasını samtools1 ile benzer bir format olan BAM dosyasına çevirip, daha sonra da bam2fastq2 aracı ile FASTQ dosyamı elde edeceğim.</description>
    </item>
    
    <item>
      <title>İlk Adım: Eşleşmeyen Okumaları Elde Etmek</title>
      <link>https://www.gungorbudak.com/blog/2012/07/04/ilk-adim-eslesmeyen-okumalari-elde/</link>
      <pubDate>Wed, 04 Jul 2012 19:48:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/04/ilk-adim-eslesmeyen-okumalari-elde/</guid>
      <description>Projemin ilk kısmı daha önce bahsettiğim gibi eşleşmeyen okumaları (unmapped reads) FASTQ dosyasından çıkarmak. Böylece, daha sonraki analizler için elimdeki ihtiyacım olmayan dizileri çıkarmış ve bu analizlerdeki iş yükünü azaltmış oluyorum.
Başından beri hedefim, tüm projeyi adım adım gerçekleştiren bir pipeline tasarlamak olduğu için bu işlemi bir Perl scripti ile yapacağım. Bu script pipeline&amp;rsquo;in ilk scripti ve laboratuvardan gelecek ham (raw) FASTQ formatındaki verinin girdi (input) olarak kullanılacağı yer. Aslında bu scripte ihtiyacım olmayacak, sadece elimdeki verinin eşlenebilen verileri de içermesi sebebiyle bu adımı ekledim.</description>
    </item>
    
    <item>
      <title>Blog Yazılarını Facebook Twitter ve LinkedIn&#39;e Yönlendirmek</title>
      <link>https://www.gungorbudak.com/blog/2012/07/02/blog-yazilarini-facebook-twitter-ve/</link>
      <pubDate>Mon, 02 Jul 2012 14:08:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/07/02/blog-yazilarini-facebook-twitter-ve/</guid>
      <description>İlgilendiğim bir konu üzerine bir blog açıp, bilgilendirici yazılar yazmak uzun süredir aklımda olan bir şeydi. Sonunda ufak ufak yazılarıma başladım. Umarım şu ana kadar güzel gitmiştir.
Bu yazıda blog başlığıyla çok alakalı olmayan &amp;ldquo;konu-dışı&amp;rdquo; bir konudan bahsedeceğim.
Yazılarımı kolay bir şekilde geniş kitleye ulaştırmak için sosyal medyayı kullanmak istiyordum ama her seferinde yazının bağlantısını kopyala-yapıştır yapmak hiç de basit bir iş değil.
Aramalarım sonunda bunu, blogumuzu Facebook, Twitter ve LinkedIn hesaplarımıza bağlayarak aynı anda yeni yazıları yönlendirebildiğimiz bir araç buldum.</description>
    </item>
    
    <item>
      <title>MegaBLAST - Dizilerdeki Benzerlikleri Bulma Aracı</title>
      <link>https://www.gungorbudak.com/blog/2012/06/28/megablast-dizilerdeki-benzerlikleri/</link>
      <pubDate>Thu, 28 Jun 2012 10:49:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/06/28/megablast-dizilerdeki-benzerlikleri/</guid>
      <description>MegaBLAST, HUSAR paketinde bulunan, BLAST (Basic Local Alignment Search Tool) paketinin bir parçası. Ayrıca BLASTN&amp;rsquo;in bir değişik türü. MegaBLAST uzun dizileri BLASTN&amp;rsquo;den daha etkili bir şekilde işliyor ve hem de çok daha hızlı işlem yapiyor ancak daha az duyarlı. Bu yüzden benzer dizileri geniş veri tabanlarında aramaya çok uygun bir araç.
Yazacağım program çoklu dizilim barındıran FASTA dosyasını alacak ve megablast komutunu çalıştıracak. Daha sonra da her okuma için bir .</description>
    </item>
    
    <item>
      <title>Kontaminant (Kirletici) Analizi Projesi</title>
      <link>https://www.gungorbudak.com/blog/2012/06/27/kontaminant-kirletici-analizi-projesi/</link>
      <pubDate>Wed, 27 Jun 2012 11:24:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/06/27/kontaminant-kirletici-analizi-projesi/</guid>
      <description>Başlangıç olarak, araçlara, programlama diline, kısacası biyoenformatiğe alışabilmem için bana verilen bu ufak projeyi ayrıntılı olarak anlatacağım.
Biliyoruz ki, laboratuvar çalışmalarımızda ne kadar önlemeye çalışsak da kontaminant riski hep bulunuyor. Bunu ne kadar aza indirsek o kadar iyi, ki daha sonra bunun miktarını bulup, bunun üzerinden sonucumuzun bir başka değerlendirmesini de yapabiliriz. İşte bunu bulmak için bir yöntem, DNA analizi. Çalıştığınız örneğinizin DNA&amp;rsquo;sı dizileniyor ve bu DNA çeşitli programlarla analiz edilip, kirleten organizmaları DNA&amp;rsquo;larından ortaya çıkarabiliyoruz</description>
    </item>
    
    <item>
      <title>FASTQ Formatı - FASTQ Dosyası</title>
      <link>https://www.gungorbudak.com/blog/2012/06/25/fastq-format-fastq-dosyasi/</link>
      <pubDate>Mon, 25 Jun 2012 11:01:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/06/25/fastq-format-fastq-dosyasi/</guid>
      <description>Bugün programı oluştururken kullanacağım &amp;ldquo;test&amp;rdquo; dizilimini aldım. İki adet FASTQ dosyasından oluşuyor, her biri sıkıştırılmış ama buna rağmen boyutları 6 GB civarı. Ben elbette çok zaman kaybetmek istemediğim için bu dosyalardan birinin sadece bir kısmını kullanacağım.
Amacım, bu FASTQ dosyalarındaki eşleşebilen okumaları BWA aracı ile bularak, daha sonra onları çıkarmak. Ve kalan eşleşemeyen okumaları MegaBLAST aracının anlayabileceği bir dilde (FASTA formatında) kaydetmek.
Bu arada tüm projeyi bir Unix bilgisayarda hazırladığım için birçok komut öğreniyorum, daha sonra bunları ayrıca yazmaya çalışacağım.</description>
    </item>
    
    <item>
      <title>BWA (Burrows-Wheeler Aligner) Hizalayıcı - Eşleştirici</title>
      <link>https://www.gungorbudak.com/blog/2012/06/22/bwa-burrows-wheeler-aligner-hizalayici/</link>
      <pubDate>Fri, 22 Jun 2012 19:21:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/06/22/bwa-burrows-wheeler-aligner-hizalayici/</guid>
      <description>Önceki yazımda belirttiğim gibi bir eşleştirici (aligner ya da mapper) kullanarak elimdeki verinin referans genomu ile ne derece eşlestiğini bulmaya çalışacağım. Daha sonra eşleşmeyen kısmıyla birtakım analizler yapacağım.
BWA (Burrows-Wheeler Aligner) görece kısa dizilimleri insan genomu gibi uzun referans genomlarıyla eşleştiren bir program. 200bp (bp: baz çifti) uzunluğuna kadar bwa-short algoritması, 200bp - 100kbp arası ise BWA-SW algoritması kullanılıyor.
Hizalayıcı - eşleştirici seçmede birçok faktör rol oynuyor. Birçok bu tip araç var ve farklı özelliklere sahipler.</description>
    </item>
    
    <item>
      <title>Dizileme Çalışmalarını Kirleten Organizmaları Tespit Etme</title>
      <link>https://www.gungorbudak.com/blog/2012/06/20/dizileme-calismalarini-kirleten/</link>
      <pubDate>Wed, 20 Jun 2012 13:46:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/06/20/dizileme-calismalarini-kirleten/</guid>
      <description>Bu yaz stajımda ilk olarak başlayacağım çalışma yavaş yavaş şekilleniyor. Bu çalışmada bir pipeline oluşturup, bunu laboratuvarlarda dizileme (sequencing) örneklerini kirleten organizmaları bulmaya çalışacağım.
Laboratuvarlarda birçok nedenden dolayı örnekler başka organizmalar ya da yabancı DNA tarafından kirlenebiliyor. Bunlar bakteri, maya olabilir ya da bir virüs DNA&amp;rsquo;sı da olabilir. Siz bir DNA&amp;rsquo;yı diziledikten sonra onun referansıyla eşleştirme çok az oranda çıkabiliyor. Bu da yabancı DNA&amp;rsquo;nın olabileceğini gösteriyor. Bir başka neden referans DNA&amp;rsquo;nın farklı olması da olabilir.</description>
    </item>
    
    <item>
      <title>Pipeline ve Pipeline Geliştirme</title>
      <link>https://www.gungorbudak.com/blog/2012/06/20/pipeline-ve-pipeline-gelistirme/</link>
      <pubDate>Wed, 20 Jun 2012 13:12:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/06/20/pipeline-ve-pipeline-gelistirme/</guid>
      <description>Bugün aldığım tanıtım derslerinin devamında, pipeline ve pipeline geliştirme ile ilgili ayrıntılı bilgiler aldım. Pipeline, aslında bildiğimiz boru hattı demek, örneğin borularla petrolün bir yerden başka bir yere taşınması için kullanılan sistem. Bunun bilgisayar terminolojisinde anlamı ise bir elementin çıktısı, diğerinin girdisi olacak şekilde oluşturulmuş işleme elementleri zinciri. Böylece çok daha komplike işlemler pipeline oluşturularak, kolay ve düzenli bir biçimde gerçekleştiriliyor. Sanırım pipeline Türkçeye ardışık düzen olarak çevriliyor, gene de ben pipeline olarak kullanacağım.</description>
    </item>
    
    <item>
      <title>WWW2HUSAR - HUSAR&#39;ın Web Arayüzü</title>
      <link>https://www.gungorbudak.com/blog/2012/06/19/www2husar-husarn-web-arayuzu/</link>
      <pubDate>Tue, 19 Jun 2012 16:55:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/06/19/www2husar-husarn-web-arayuzu/</guid>
      <description>Stajımın ikinci gününde HUSAR&amp;rsquo;ın web arayüzünü konuştuk. HUSAR komut isteminden komutlarla kullanılabilen, yönetilebilen bir yazılım ancak bunu kolaylaştırmak için hazırlanmış bir web arayüzü var. WWW2HUSAR adını verdikleri bu arayüz ile listelenen araçları kolayca seçebiliyor, genetik dizinizi ekleyebiliyor ve başka birçok işlemi kolayca, birkaç tık ile yapabiliyorsunuz.
Bununla birlikte biraz daha HUSAR&amp;rsquo;ın işlevlerine göz attık. Yazılımda, yerel klasörde gen dizisi listeleri oluşturarak, bunları çoklu dizi hizalama (multiple sequence alignment) aracı ile genlerin benzerliklerini karşılastırabiliyor ve örneğin evrimsel ilişkilerini ortaya çıkarabiliyorsunuz.</description>
    </item>
    
    <item>
      <title>DKFZ - Heidelberg Biyoenformatik Birimi&#39;nde Staj</title>
      <link>https://www.gungorbudak.com/blog/2012/06/18/dkfz-heidelberg-biyoenformatik/</link>
      <pubDate>Mon, 18 Jun 2012 16:39:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/06/18/dkfz-heidelberg-biyoenformatik/</guid>
      <description>Erasmus programıyla yapıyor olduğum yaz stajı başladı. İlk olarak birimi yöneten bilim insanlarından birkaç saatlik tanıtım dersi aldım. Bu derste birimin kısa tarihi, birimin günümüze kadar yaptıkları projeler ve bunlarin ayrintilari konusunda bilgiler aldım.
Biyoenformatik Birimi DKFZ&amp;rsquo;nin (Deutsches Krebsforschungszentrum &amp;ndash; ing. German Cancer Research Center) bir çekirdek tesisi olan Genomik ve Proteomik Çekirdek Tesisi&amp;rsquo;ne bağlı bir grup. İsimleri aynı zamanda HUSAR (Heidelberg Unix Sequence Analysis Resources) ve bu isim grubun geliştirdiği dizi analizi yapma paketinin de adı olarak kullanılıyor.</description>
    </item>
    
    <item>
      <title>Biyoinformatik mi? Yoksa Biyoenformatik mi?</title>
      <link>https://www.gungorbudak.com/blog/2012/03/18/biyoinformatik-mi-yoksa-biyoenformatik/</link>
      <pubDate>Sun, 18 Mar 2012 18:00:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/03/18/biyoinformatik-mi-yoksa-biyoenformatik/</guid>
      <description>Yazılarıma konu ararken kitaplarla birlikte interneti de karıştırıyorum. Yabancı kaynaklar elbette fazlaca var ve yeterliler, ancak Türkçe kaynaklara baktığımda ilk gözüme çarpan bu alanın isminin farklı kullanımları oldu.
Biliyorsunuz, İngilizcede bu alana bioinformatics deniyor. Gayet normal, çünkü İngilizcede informatics ics eki ile birlikte information sözcüğünden geliyor. Bu sözcük ise Latince kökene sahip1. Enformatik sözcüğü Türkçeye, Fransızcadan informatique sözcüğünden, enformatik olarak gelmiş, ayrıca bilişim olarak da Türkçesi önerilmiş2. Elbette bu Fransızca sözcük de İngilizcesi ile aynı kökene sahip.</description>
    </item>
    
    <item>
      <title>7th International Symposium on Health Informatics and Bioinformatics</title>
      <link>https://www.gungorbudak.com/blog/2012/03/17/7th-international-symposium-on-health/</link>
      <pubDate>Sat, 17 Mar 2012 17:14:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/03/17/7th-international-symposium-on-health/</guid>
      <description>7. Sağlık Enformatiği ve Biyoenformatik üzerine Uluslararası Sempozyumu, 7th International Symposium on Health Informatics and Bioinformatics (HIBIT 2012), ilk kez 2005&amp;rsquo;te ODTÜ Enformatik Enstitüsü tarafından düzenlenmiş ve Sağlık Enformatiği, Tıbbi Enformatik, Hesaplamalı Biyoloji ve Biyoenformatik alanlarında akademisyenleri ve araştırmacıları bir araya getirmeyi ve bu alanlar hakkında yapılan çalışmaların sunulmasına ortam sağlamayı ve çalışmalar üzerine interaktif bir şekilde değerlendirmeler yapmayı amaçlamaktadır.
Bu sene, 19-22 Nisan 2012&amp;rsquo;de Ürgüp, Nevşehir Perissia Hotel&amp;rsquo;de düzenlenecek olan HIBIT 2012 organizasyonu ODTÜ, ODTÜ Enformatik Enstitüsü, ODTÜ Biyolojik Bilimler Bölümü ve ODTÜ Bilgisayar Mühendisliği Bölümü partnerliği ile gerçekleştirilmektedir.</description>
    </item>
    
    <item>
      <title>Biyoenformatik Nedir? Biyoenformatik&#39;in Tanımı</title>
      <link>https://www.gungorbudak.com/blog/2012/03/16/biyoenformatik-nedir-biyoenformatikin-tanimi/</link>
      <pubDate>Fri, 16 Mar 2012 17:59:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/03/16/biyoenformatik-nedir-biyoenformatikin-tanimi/</guid>
      <description>Birçok organizmanın ve son olarak da 2001&amp;rsquo;de insan genomunun çıkarılmasıyla, tüm 3 milyar baz çiftinin diziliminin elde edilmesiyle, karşımıza bu bilgiyi farklı şekillerde kullanacak olan alanlar çıktı.Bu genleri anlamaya çalışan, bu genlerden oluşacak proteinleri belirlemeye çalışan alanların yanında bu bilginin analizini yapma ihtiyacı da Biyoenformatik alanını doğurdu.
Biyoenformatik, biyolojik bilginin bilgisayarlar ve istatistiksel teknikler kullanılarak analiz edilmesidir; başka bir deyişle, biyoenformatik, biyolojik araştırmaları iyileştirmek ve hızlandırmak için bilgisayar veri tabanları ve algoritmaları geliştirme ve onlardan yarar sağlama bilimidir [1].</description>
    </item>
    
    <item>
      <title>Hoş Geldim! Hoş Geldiniz!</title>
      <link>https://www.gungorbudak.com/blog/2012/03/16/hos-geldim-hos-geldiniz/</link>
      <pubDate>Fri, 16 Mar 2012 17:40:00 +0300</pubDate>
      
      <guid>https://www.gungorbudak.com/blog/2012/03/16/hos-geldim-hos-geldiniz/</guid>
      <description>Merhabalar,
Biyoloji alanında özel olarak ilgi alanım olan ve daha fazla keşfetmem, üzerine çok şey öğrenmem gereken Biyoenformatik&amp;rsquo;i, bu blog aracılığıyla (olası ziyaretçilerimle birlikte) öğreneceğim. İlk yazımı biraz önce Biyoenformatik&amp;rsquo;in çeşitli otoriteler tarafından yapılan tanımları ile tamamladım. Daha sonra, Biyoenformatik&amp;rsquo;te geçen birçok ilkelerin tanımlarından da bahsetmek istiyorum. Ayrıca, Biyoenformatik hakkında yazılım dilleri, istatiksel yöntemler de yazılarımın konularını oluşturacak. Aynı zamanda Biyoenformatik ile ilgili haberlere de yer vermek ve bu haberlerle en son gelişmeleri takip etmeyi (ettirmeyi) planlıyorum.</description>
    </item>
    
  </channel>
</rss>
